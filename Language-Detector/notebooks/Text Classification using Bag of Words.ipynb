{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Text Classification using Bag of Words.ipynb","provenance":[{"file_id":"/v2/external/notebooks/basic_features_overview.ipynb","timestamp":1585794556190}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"da84faf22d3b4fbebe17868cc210352e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c301370c81e5405299fdb049e8df3dae","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_14f1fd54e9c44091aa1af4b5c5bd5d4c","IPY_MODEL_a87d37ec3dd04568b53fc2c9cdb262e5"]}},"c301370c81e5405299fdb049e8df3dae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"14f1fd54e9c44091aa1af4b5c5bd5d4c":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_cfcb23d65b684cb68d1e8629c4459bb7","_dom_classes":[],"description":"100%","_model_name":"IntProgressModel","bar_style":"success","max":1021889,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1021889,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4dd2eb6ad2ca4c238e775a5e391fca9c"}},"a87d37ec3dd04568b53fc2c9cdb262e5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0bdf0eccd0804659a0e8ab64923bf599","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1021889/1021889 [02:12&lt;00:00, 7691.16it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8cfaa4a02a794352a7337332bef86379"}},"cfcb23d65b684cb68d1e8629c4459bb7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4dd2eb6ad2ca4c238e775a5e391fca9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0bdf0eccd0804659a0e8ab64923bf599":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8cfaa4a02a794352a7337332bef86379":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2ef8a0b1350b47aba51fd8e7690f9bf6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6c45c9dc28ae4dc68d6f361f1c00e875","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b7a62e31b316462ea16533efc87a0223","IPY_MODEL_b1700cfe4f994145a83a35f8d2166d92"]}},"6c45c9dc28ae4dc68d6f361f1c00e875":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b7a62e31b316462ea16533efc87a0223":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c237415f24b848feb58275704746dd23","_dom_classes":[],"description":"100%","_model_name":"IntProgressModel","bar_style":"success","max":1021889,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1021889,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5b66d85675b5496ba037957dc9f6a2b3"}},"b1700cfe4f994145a83a35f8d2166d92":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3c60c51d11174fd8b1e0be8504a3f9ca","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1021889/1021889 [04:08&lt;00:00, 4104.44it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_275b2caf37f64dc3b5ddc286838225e7"}},"c237415f24b848feb58275704746dd23":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5b66d85675b5496ba037957dc9f6a2b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3c60c51d11174fd8b1e0be8504a3f9ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"275b2caf37f64dc3b5ddc286838225e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2d8cd771a9c84b1cb2921b5e1de9a4a0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ca628f94a50144fd9427ddbd790d4ec3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2fc7813e704047aa8730b742d02e9890","IPY_MODEL_e73f23f3f6b44a849feb78faa8eb725d"]}},"ca628f94a50144fd9427ddbd790d4ec3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2fc7813e704047aa8730b742d02e9890":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_833225bcfa994e5885d93e8b5c28bd09","_dom_classes":[],"description":"100%","_model_name":"IntProgressModel","bar_style":"success","max":256058,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":256058,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_48237ad097a04913ad75597c5773b3af"}},"e73f23f3f6b44a849feb78faa8eb725d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d3e08b5db406470d94ae670782285e8c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 256058/256058 [01:29&lt;00:00, 2845.92it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_57414c7c718c43d1996cd52c6d340d10"}},"833225bcfa994e5885d93e8b5c28bd09":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"48237ad097a04913ad75597c5773b3af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d3e08b5db406470d94ae670782285e8c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"57414c7c718c43d1996cd52c6d340d10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d0e66fc48e334e9682072c8a05c695ad":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ffffcab8c96f482a96dd1e2641666275","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_38547a52aa5a4e8fac09346158a0c583","IPY_MODEL_05d688c1526246b3b3a65d162054c9fc"]}},"ffffcab8c96f482a96dd1e2641666275":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"38547a52aa5a4e8fac09346158a0c583":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e32662a9cc3c42fbb9d80d548fc3534d","_dom_classes":[],"description":"100%","_model_name":"IntProgressModel","bar_style":"success","max":256058,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":256058,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9f359e7702204f6e87bc67a0f8722772"}},"05d688c1526246b3b3a65d162054c9fc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e35b444a63234f38b7ea71de0fce58be","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 256058/256058 [00:51&lt;00:00, 4994.24it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7411d5477f2342aa891f9cf17ea46c2c"}},"e32662a9cc3c42fbb9d80d548fc3534d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9f359e7702204f6e87bc67a0f8722772":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e35b444a63234f38b7ea71de0fce58be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7411d5477f2342aa891f9cf17ea46c2c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3493f1a4cb63457db60846c2fc805e03":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a4f2c1a836a44661adbf742771f27584","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7f70074094044edfa2c83c0b36b52500","IPY_MODEL_4c6c74ee024a44b9bd737da672f0f3d5"]}},"d4e052e7596541fbb9b47423c2db7397":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e6c9fcdf80774f75bb989e67c7dc710e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d74188e79d054ea5baaf1605fbdab9e3","IPY_MODEL_d1a8da9653d64cfbb18d2439e7f7cdec"]}},"e6c9fcdf80774f75bb989e67c7dc710e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d74188e79d054ea5baaf1605fbdab9e3":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b7cc2a94570b404184a34ecd5893df99","_dom_classes":[],"description":"100%","_model_name":"IntProgressModel","bar_style":"success","max":16001,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":16001,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_60c1bcaf244d4c81a842a16387038207"}},"d1a8da9653d64cfbb18d2439e7f7cdec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_df7aaceb2efb4be78ff9cc27a65e99fb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 16001/16001 [01:28&lt;00:00, 181.74it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_95fb768f956a4fbcba6b275f306e2685"}},"b7cc2a94570b404184a34ecd5893df99":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"60c1bcaf244d4c81a842a16387038207":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"df7aaceb2efb4be78ff9cc27a65e99fb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"95fb768f956a4fbcba6b275f306e2685":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"x0we8fZWoGDM","colab_type":"text"},"source":["## **Prerequisites**"]},{"cell_type":"markdown","metadata":{"id":"a6NKRHHQuYYj","colab_type":"text"},"source":["### **Check what GPU you got**\n","If you didn't get the P100-PCIE GPU, click on the Runtime dropdown at the top of the page and Factory Reset Runtime "]},{"cell_type":"code","metadata":{"id":"k6IsoceZuXEA","colab_type":"code","outputId":"46b71da3-0d0e-4a13-8cf7-816d39846511","executionInfo":{"status":"ok","timestamp":1588293533624,"user_tz":240,"elapsed":1444,"user":{"displayName":"Emilio Kartono","photoUrl":"","userId":"07780560173057852230"}},"colab":{"base_uri":"https://localhost:8080/","height":306}},"source":["!nvidia-smi"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Fri May  1 00:38:52 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   37C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"laSX84MxurOt","colab_type":"text"},"source":["### **Mount and Install Packages**\n","Mount the data and set up Spacy\n"]},{"cell_type":"code","metadata":{"id":"U9ayjBQKuvyi","colab_type":"code","outputId":"ebb2a3fb-5750-41d7-a8c5-2cc4d3119636","executionInfo":{"status":"ok","timestamp":1588293578585,"user_tz":240,"elapsed":33373,"user":{"displayName":"Emilio Kartono","photoUrl":"","userId":"07780560173057852230"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","!python -m spacy download en_core_web_sm\n","!python -m spacy download fr_core_news_sm"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n","Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n","Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.3)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.38.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (46.1.3)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.6.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.4.5.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_sm')\n","Collecting fr_core_news_sm==2.2.5\n","\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.2.5/fr_core_news_sm-2.2.5.tar.gz (14.7MB)\n","\u001b[K     |████████████████████████████████| 14.7MB 1.7MB/s \n","\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from fr_core_news_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.6.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.0.3)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.23.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (46.1.3)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.18.3)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.2)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.38.0)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.2)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2020.4.5.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.4)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.6.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.1.0)\n","Building wheels for collected packages: fr-core-news-sm\n","  Building wheel for fr-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fr-core-news-sm: filename=fr_core_news_sm-2.2.5-cp36-none-any.whl size=14727027 sha256=a56eb8da8223ce3f1349f6b96f08e2e27e05e3c09731c1f1a66f5ad405fe7e45\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-2e6jnp4b/wheels/46/1b/e6/29b020e3f9420a24c3f463343afe5136aaaf955dbc9e46dfc5\n","Successfully built fr-core-news-sm\n","Installing collected packages: fr-core-news-sm\n","Successfully installed fr-core-news-sm-2.2.5\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('fr_core_news_sm')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IZSmGbR69WHJ","colab_type":"text"},"source":["### **Important: Reset Runtime**\n","\n","Note: there is a slight bug with Google Colab. After installing Spacy, you need to restart the Jupyter Notebook runtime.\n","\n","There are two ways:\n","1. Click on the Runtime dropdown, and select \"Restart Runtime\". Once that is done, proceed to the next step (no need to remount the drive).\n","2. Run the code below. It will kill the current process, effectively restarting the runtime."]},{"cell_type":"code","metadata":{"id":"CNqV5Lpl9Qby","colab_type":"code","colab":{}},"source":["import os\n","os.kill(os.getpid(), 9)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HeUezX16XqbW","colab_type":"text"},"source":["##Get the data"]},{"cell_type":"markdown","metadata":{"id":"1P6YAlBjvGJc","colab_type":"text"},"source":["### **Get a list of vocabs:**\n","The list of vocabs are already stored in the Google Drive folder; thus, we just have to load it."]},{"cell_type":"code","metadata":{"id":"l9y65pEZvJqO","colab_type":"code","outputId":"0868d3e0-760d-4a47-a186-951b57e438a7","executionInfo":{"status":"ok","timestamp":1588297098172,"user_tz":240,"elapsed":1803,"user":{"displayName":"Emilio Kartono","photoUrl":"","userId":"07780560173057852230"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["import sys\n","sys.path.append('/content/drive/My Drive/Translator/src/dataloader/')\n","\n","\n","def get_size_of_corpus(filepaths):\n","    \"\"\" Given a list of filepaths, it will return the total number of lines\n","\n","        Parameters\n","        ----------\n","        filepaths : [ str ]\n","            A list of filepaths\n","\n","        Returns\n","        -------\n","        num_lines : int\n","            The total number of lines in filepaths\n","    \"\"\"\n","\n","    def blocks(files, size=65536):\n","        while True:\n","            b = files.read(size)\n","            if not b:\n","                break\n","            yield b\n","\n","    num_lines = 0\n","    for filepath in filepaths:\n","        with open(filepath, encoding=\"utf-8\") as f:\n","            num_lines += sum(bl.count(\"\\n\") for bl in blocks(f))\n","\n","    return num_lines\n","\n","\n","def get_tokens_from_line(line, spacy_instance):\n","    global PUNCTUATION_TABLE, LEGAL_CHARS_TABLE, LEGAL_CHARS\n","\n","    # Make the text lowercase and remove the \\n\n","    line = line.lower().strip()\n","\n","    # Standardize single quotations\n","    line = (\n","        line.replace(\"\\u2019\", \"'\")\n","        .replace(\"\\u0060\", \"'\")\n","        .replace(\"\\u00B4\", \"'\")\n","        .replace(\"\\u2018\", \"'\")\n","        .replace(\"\\u201A\", \"'\")\n","        .replace(\"\\u201B\", \"'\")\n","        .replace(\"\\u2039\", \"'\")\n","        .replace(\"\\u203A\", \"'\")\n","        .replace(\"\\u275B\", \"'\")\n","        .replace(\"\\u275C\", \"'\")\n","        .replace(\"\\u276E\", \"'\")\n","        .replace(\"\\u276F\", \"'\")\n","    )\n","\n","    # Standardize dashes\n","    line = (\n","        line.replace(\"\\u00AD\", \"-\")\n","        .replace(\"\\u2013\", \"-\")\n","        .replace(\"\\u2014\", \"-\")\n","        .replace(\"\\u2015\", \"-\")\n","        .replace(\"\\u2212\", \"-\")\n","        .replace(\"\\u02D7\", \"-\")\n","    )\n","\n","    # Standardize double quotations\n","    line = (\n","        line.replace(\"\\u201C\", '\"')\n","        .replace(\"\\u201D\", '\"')\n","        .replace(\"\\u2033\", '\"')\n","        .replace(\"\\u00AB\", '\"')\n","        .replace(\"\\u00BB\", '\"')\n","        .replace(\"\\u201E\", '\"')\n","        .replace(\"\\u201F\", '\"')\n","        .replace(\"\\u275D\", '\"')\n","        .replace(\"\\u275E\", '\"')\n","        .replace(\"\\u301D\", '\"')\n","        .replace(\"\\u301E\", '\"')\n","        .replace(\"\\u301F\", '\"')\n","        .replace(\"\\uFF02\", '\"')\n","    )\n","\n","    # Standardize the ellipses\n","    line = line.replace(\"\\u2026\", \"...\")\n","\n","    # Tokenize the text\n","    tokens = spacy_instance.tokenizer(line)\n","\n","    # Remove tokens that are spaces, tabs, newlines, etc\n","    tokens = list(filter(lambda token: not token.is_space, tokens))\n","\n","    # Extract only the text\n","    tokens = [token.text for token in tokens]\n","\n","    # Replace tokens that contain numbers with 'NUM'\n","    num_vals = []\n","    new_tokens = []\n","    for token in tokens:\n","        new_token = token\n","\n","        if any(char.isdigit() for char in token):\n","            new_token = \"NUM\"\n","            num_vals.append(token)\n","\n","        new_tokens.append(new_token)\n","    \n","    tokens = new_tokens\n","\n","    return tokens, num_vals\n","\n","\n","def read_transcription_files(filepaths, spacy_instance):\n","    \"\"\" Generate line info from data in a file for a given language\n","\n","        Parameters\n","        ----------\n","        lang : {'en', 'fr'}\n","            Whether to tokenize the English sentences ('e') or French ('f').\n","        filenames : sequence\n","            Only tokenize sentences with matching names. If :obj:`None`, searches\n","            the whole directory in C-sorted order.\n","\n","        Yields\n","        ------\n","        tokenized, filename, offs : list\n","            `tokenized` is a list of tokens for a line. `filename` is the source\n","            file. `offs` is the start of the sentence in the file, to seek to.\n","            Lines are yielded by iterating over lines in each file in the order\n","            presented in `filenames`.\n","    \"\"\"\n","    for filepath in filepaths:\n","        with open(filepath, encoding=\"utf-8\") as f:\n","            offs = f.tell()\n","            line = f.readline()\n","            while line:\n","                tokens, _ = get_tokens_from_line(line, spacy_instance)\n","\n","                yield tokens, filepath, offs\n","                offs = f.tell()\n","                line = f.readline()\n","\n","\n","def get_parallel_text(dir_, langs):\n","    \"\"\" Get a list of all files in 'dir_' with a file extension that is in 'langs'\n","\n","        Parameters\n","        ----------\n","        dir_ : str\n","            A path to the transcription dictionary\n","        langs : [str]\n","            A list of file extensions for the parallel texts\n","\n","        Returns\n","        -------\n","        filenames : list\n","            A list of all parallel texts' file names without the file extension\n","    \"\"\"\n","    # Get a set of files that has the lang file extension\n","    files = os.listdir(dir_)\n","    filenames = []\n","    for lang in langs:\n","        lang = \".\" + lang\n","        lang_filenames = set(\n","            filename[:-3] for filename in files if filename.endswith(lang)\n","        )\n","        filenames.append(lang_filenames)\n","    del files\n","\n","    if len(filenames) == 0:\n","        raise ValueError(\n","            f\"Directory {dir_} contains no transcriptions ending in {lang} \"\n","        )\n","\n","    # Get the set of files that has the same name\n","    transcriptions_filenames = filenames[0]\n","    for lang_filenames in filenames:\n","        transcriptions_filenames = transcriptions_filenames & lang_filenames\n","\n","    transcriptions_filenames = sorted(transcriptions_filenames)\n","\n","    if len(transcriptions_filenames) == 0:\n","        raise ValueError(\n","            f\"Directory {dir_} contains no common files ending in {lang}.\"\n","            f\"Are you sure this is the right directory?\"\n","        )\n","\n","    # Create the output\n","    parallel_text = []\n","    for filename in transcriptions_filenames:\n","        parallel_text.append(tuple([filename + \".\" + lang for lang in langs]))\n","\n","    return parallel_text\n","\n","\n","def get_spacy_instance(lang, spacy_namespace=None):\n","    \"\"\" Returns the correct Spacy instance given the lang ISO.\n","        If the namespace is provided, it will use the namespace instead\n","\n","        Parameters\n","        ----------\n","        lang : { 'en', 'fr' }\n","            The lang ISO\n","        spacy_namespace : str, optional\n","            The Spacy namespace\n","\n","        Returns\n","        -------\n","        spacy_instance : Spacy\n","            The Spacy instance with the correct language\n","    \"\"\"\n","    if spacy_namespace is None:\n","        if lang == \"en\":\n","            spacy_namespace = \"en_core_web_sm\"\n","        elif lang == \"fr\":\n","            spacy_namespace = \"fr_core_news_sm\"\n","        else:\n","            raise Exception(\"Unknown language: \" + lang)\n","\n","    spacy_instance = spacy.load(spacy_namespace, disable=[\"parser\", \"ner\"])\n","    # spacy_instance.add_pipe(spacy_instance.create_pipe(\"sentencizer\"))\n","\n","    return spacy_instance\n","\n","class VocabDataset:\n","    def __init__(self, word2id={}, id2word={}):\n","        \"\"\"\n","            Initializes the Vocab dataset\n","\n","            Parameters\n","            ----------\n","            word2id : { str : int }, optional\n","                A mapping of words to their ID\n","\n","            id2word : { str : int }, optional\n","                A mapping of IDs to their words\n","        \"\"\"\n","\n","        self.word2id = word2id\n","        self.id2word = id2word\n","\n","    def get_id2word(self):\n","        \"\"\" Returns a dictionary mapping an ID to a word\n","\n","            Returns\n","            -------\n","            dictionary : { int : str }\n","                key is the ID of the word, and its value is the word itself\n","        \"\"\"\n","        return self.id2word\n","\n","    def get_word2id(self):\n","        \"\"\" Returns a dictionary mapping a word to an ID\n","\n","            Returns\n","            -------\n","            dictionary : { str : int }\n","                key is the word itself, and its value is the ID of the word\n","        \"\"\"\n","        return self.word2id\n","\n","\n","def load_vocabs_from_file(file_):\n","    \"\"\" Read self.word2id map from a file\n","\n","        Parameters\n","        ----------\n","        file_ : str or file\n","            A file to read `word2id` from. If a path that ends with ``.gz``, it\n","            will be de-compressed via gzip.\n","    \"\"\"\n","    if isinstance(file_, str):\n","        if file_.endswith(\".gz\"):\n","            with gzip.open(file_, mode=\"rt\", encoding=\"utf8\") as file_:\n","                return load_vocabs_from_file(file_)\n","        else:\n","            with open(file_, encoding=\"utf8\") as file_:\n","                return load_vocabs_from_file(file_)\n","\n","    word2id = dict()\n","    id2word = dict()\n","\n","    for line in file_:\n","        line = line.strip()\n","        if not line:\n","            continue\n","\n","        tokens = line.split()\n","\n","        if len(tokens) == 2:\n","            word, id_ = tokens[0], tokens[1]\n","            id_ = int(id_)\n","\n","            if id_ in id2word:\n","                raise ValueError(f\"Duplicate id {id_}\")\n","            if word in word2id:\n","                raise ValueError(f\"Duplicate word {word}\")\n","\n","            word2id[word] = id_\n","            id2word[id_] = word\n","\n","        else:\n","            raise Exception(\"Illegal vocab:\", line)\n","\n","    print(\"Loaded\", len(word2id), \"words\")\n","\n","    return VocabDataset(word2id, id2word)\n","\n","\n","def save_vocabs_to_file(vocabs, file_):\n","    \"\"\" Write vocabs.word2id map to a file\n","\n","        Parameters\n","        ----------\n","        vocabs : VocabDataset\n","            The dataset to save\n","        file_ : str or file\n","            A file to write `word2id` to. If a path that ends with ``.gz``, it will be gzipped.\n","    \"\"\"\n","    if isinstance(file_, str):\n","        if file_.endswith(\".gz\"):\n","            with gzip.open(file_, mode=\"wt\", encoding=\"utf8\") as file_:\n","                return save_vocabs_to_file(vocabs, file_)\n","        else:\n","            with open(file_, \"w\", encoding=\"utf8\") as file_:\n","                return save_vocabs_to_file(vocabs, file_)\n","\n","    id2word = vocabs.get_id2word()\n","    for i in range(len(id2word)):\n","        line = \"{} {}\\n\".format(id2word[i], i)\n","        file_.write(line)\n","\n","\n","def build_vocabs_from_dir(\n","    train_dir_, lang, spacy_namespace=None, max_vocab=float(\"inf\"), min_freq=0\n","):\n","  \"\"\" Build a vocabulary (words->ids) from transcriptions in a directory\n","\n","      Parameters\n","      ----------\n","      train_dir_ : str\n","          A path to the transcription directory. ALWAYS use the training\n","          directory, not the test, directory, when building a vocabulary.\n","\n","      lang : {'en', 'fr'}\n","          Whether to build the English vocabulary ('e') or the French one ('f').\n","\n","      spacy_namespace : str\n","          It is the type of Spacy (ex: en_core_web_sm). if None, it will set\n","          it to 'en_core_web_sm' if lang is 'en'; else if 'fr' then 'fr_core_news_sm'\n","\n","      max_vocab : int, optional\n","          The size of your vocabulary. Words with the greatest count will be\n","          retained.\n","\n","      min_freq : int, optional\n","          The minimum frequency each word in the vocabulary needs to be\n","  \"\"\"\n","\n","  # Set up spacy for tokenisation\n","  spacy_instance = utils.get_spacy_instance(lang)\n","\n","  # Get the language corpus\n","  transcriptions = utils.get_parallel_text(train_dir_, [lang])\n","  filepaths = [os.path.join(train_dir_, trans[0]) for trans in transcriptions]\n","\n","  print(\"Building\", lang, \"vocab from\", len(transcriptions), \"transcriptions\")\n","\n","  # Build a counter of tokens\n","  word2count = Counter()\n","\n","  corpus = utils.read_transcription_files(filepaths, spacy_instance)\n","  corpus_size = utils.get_size_of_corpus(filepaths)\n","\n","  for tokenized, _, _ in tqdm(corpus, total=corpus_size):\n","      word2count.update(list(set(tokenized)))\n","\n","  # Filter those that meet the frequency\n","  word2count = list(\n","      filter(lambda word_count: word_count[1] >= min_freq, word2count.items())\n","  )\n","\n","  # Sort tokens in dec. frequency and cap it by max_vocab\n","  word2count = sorted(word2count, key=lambda kv: (kv[1], kv[0]), reverse=True)\n","\n","  # Cap the number of words in the corpus\n","  if len(word2count) > max_vocab:\n","      word2count = word2count[0:max_vocab]\n","\n","  word2id = dict((v[0], i) for i, v in enumerate(word2count))\n","  id2word = dict((i, v[0]) for i, v in enumerate(word2count))\n","\n","  print(\"Built\", len(word2id), \"vocabs\")\n","\n","  return VocabDataset(word2id, id2word)\n","\n","def combine_vocabs(vocab1, vocab2):\n","  combined_words = set()\n","\n","  for key in vocab1.get_word2id():\n","    combined_words.add(key)\n","\n","  for key in vocab2.get_word2id():\n","    combined_words.add(key)\n","\n","  word2id = dict((word, index) for index, word in enumerate(combined_words))\n","  id2word = dict((index, word) for index, word in enumerate(combined_words))\n","\n","  print('Built', len(word2id), 'vocabs')\n","\n","  return VocabDataset(word2id, id2word)\n","\n","models_dir = \"/content/drive/My Drive/Translator/models/Hansard/\"\n","french_vocabs = load_vocabs_from_file(models_dir + 'vocab.french.gz')\n","english_vocabs = load_vocabs_from_file(models_dir + 'vocab.english.gz')\n","\n","combined_vocabs = combine_vocabs(english_vocabs, french_vocabs)\n","combined_vocabs = sorted([word for word in combined_vocabs.get_word2id()])\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Loaded 33639 words\n","Loaded 25370 words\n","Built 52275 vocabs\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lJQ-AdsgP8ck","colab_type":"text"},"source":["### **Tokenize and split the dataset**\n","We will have three types of datasets:\n","1. Training data: it is the data used to train our model\n","2. Validation (val) data: it is the data used to test our model at each step of the training process\n","3. Test data: it is the data used to test our model after all the training is done\n","\n","How to get the three types of data?\n","* The test set is already in the `Test` folder\n","* The validation set is a piece of the data in the `Train`` folder\n","\n","The code to get our three types of datasets is:"]},{"cell_type":"code","metadata":{"id":"QgkXZrvOP72R","colab_type":"code","outputId":"dfa33279-e553-426e-b831-dc9e0442cdfd","executionInfo":{"status":"ok","timestamp":1588298628789,"user_tz":240,"elapsed":960302,"user":{"displayName":"Emilio Kartono","photoUrl":"","userId":"07780560173057852230"}},"colab":{"base_uri":"https://localhost:8080/","height":213,"referenced_widgets":["da84faf22d3b4fbebe17868cc210352e","c301370c81e5405299fdb049e8df3dae","14f1fd54e9c44091aa1af4b5c5bd5d4c","a87d37ec3dd04568b53fc2c9cdb262e5","cfcb23d65b684cb68d1e8629c4459bb7","4dd2eb6ad2ca4c238e775a5e391fca9c","0bdf0eccd0804659a0e8ab64923bf599","8cfaa4a02a794352a7337332bef86379","2ef8a0b1350b47aba51fd8e7690f9bf6","6c45c9dc28ae4dc68d6f361f1c00e875","b7a62e31b316462ea16533efc87a0223","b1700cfe4f994145a83a35f8d2166d92","c237415f24b848feb58275704746dd23","5b66d85675b5496ba037957dc9f6a2b3","3c60c51d11174fd8b1e0be8504a3f9ca","275b2caf37f64dc3b5ddc286838225e7","2d8cd771a9c84b1cb2921b5e1de9a4a0","ca628f94a50144fd9427ddbd790d4ec3","2fc7813e704047aa8730b742d02e9890","e73f23f3f6b44a849feb78faa8eb725d","833225bcfa994e5885d93e8b5c28bd09","48237ad097a04913ad75597c5773b3af","d3e08b5db406470d94ae670782285e8c","57414c7c718c43d1996cd52c6d340d10","d0e66fc48e334e9682072c8a05c695ad","ffffcab8c96f482a96dd1e2641666275","38547a52aa5a4e8fac09346158a0c583","05d688c1526246b3b3a65d162054c9fc","e32662a9cc3c42fbb9d80d548fc3534d","9f359e7702204f6e87bc67a0f8722772","e35b444a63234f38b7ea71de0fce58be","7411d5477f2342aa891f9cf17ea46c2c"]}},"source":["import sys\n","sys.path.append('/content/drive/My Drive/Translator/src/dataloader')\n","\n","import os\n","from tqdm.notebook import tqdm\n","\n","import torch\n","\n","class Seq2VecDataset(torch.utils.data.Dataset):\n","  def __init__(self, dir_: str, vocabs: list, langs: list):\n","    ''' Reads in the sentences in `dir_`, convert each word into its numerical token, \n","        and tags it with its language\n","\n","        Parameters\n","        ----------\n","        dir_ : str\n","            The directory with the training data\n","        vocabs : [ str ]\n","            A list of vocabs\n","        lang : [ str ]\n","            The set of languages to capture in `dir_`\n","    '''\n","\n","    pairs = []\n","    word2index = { word: index for index, word in enumerate(vocabs)}\n","    \n","    for lang_index, lang in enumerate(langs):\n","\n","      # Get the spacy instance\n","      spacy_instance = get_spacy_instance(lang)\n","\n","      # Get all the filenames with that language\n","      transcriptions = get_parallel_text(dir_, [lang])\n","      \n","      # Get all the filepaths with that language\n","      filepaths = [os.path.join(dir_, trans[0]) for trans in transcriptions]\n","\n","      # Get the iterator that will read and tokenize all the content in filepaths\n","      iterator = read_transcription_files(filepaths, spacy_instance)\n","\n","      # Get the number of sentences in entire corpus with that language\n","      corpus_size = get_size_of_corpus(filepaths)\n","\n","      for (f, f_fn, _), in tqdm(iterable=zip(iterator), total=corpus_size):\n","        if not f:\n","          continue\n","\n","        # Ignore sentences with no words in vocabs\n","        has_known_word = sum([1 if word in word2index else 0 for word in f]) > 0\n","        if not has_known_word:\n","          continue\n","\n","        pairs.append((f, lang_index))\n","    \n","    self.langs = langs\n","    self.vocabs = vocabs\n","    self.pairs = pairs\n","    self.word2index = word2index\n","  \n","  def __len__(self):\n","    ''' Returns the number of sentences in this dataset '''\n","    return len(self.pairs)\n","\n","  def __getitem__(self, i):\n","    ''' Returns the i-th sentence in this dataset '''\n","    f, lang_index = self.pairs[i]\n","\n","    # Get the bag of words for f where vec[i] = 1 if word i exists; else 0\n","    F = torch.zeros(len(self.vocabs))\n","    for word in f:\n","      if word in self.word2index:\n","        index = self.word2index[word]\n","        F[index] = 1\n","\n","    Y = torch.tensor(lang_index)\n","\n","    return F, Y\n","\n","utils.get_spacy_instance('fr')\n","train_dir = \"/content/drive/My Drive/Translator/data/Hansard/Training\"\n","test_dir = \"/content/drive/My Drive/Translator/data/Hansard/Testing\"\n","\n","num_epochs = 10\n","batch_size = 32\n","device = torch.device('cuda')\n","train_test_split_ratio = 0.75\n","\n","dataset = Seq2VecDataset(train_dir, combined_vocabs, ['en', 'fr'])\n","\n","num_training_data = int(len(dataset) * train_test_split_ratio)\n","num_val_data = len(dataset) - num_training_data\n","\n","train_dataset, val_dataset = torch.utils.data.random_split(\n","  dataset, [num_training_data, num_val_data]\n",")\n","\n","train_dataloader = torch.utils.data.DataLoader(\n","  train_dataset, \n","  batch_size=batch_size, \n","  shuffle=True,\n","  pin_memory=(device.type == 'cuda'),\n","  num_workers=4\n",")\n","val_dataloader = torch.utils.data.DataLoader(\n","  val_dataset, \n","  batch_size=batch_size, \n","  shuffle=True,\n","  pin_memory=(device.type == 'cuda'),\n","  num_workers=4\n",")\n","\n","test_dataset = Seq2VecDataset(test_dir, combined_vocabs, ['en', 'fr'])\n","test_dataloader = torch.utils.data.DataLoader(\n","  test_dataset, \n","  batch_size=batch_size, \n","  shuffle=True,\n","  pin_memory=(device.type == 'cuda'),\n","  num_workers=4\n",")"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"da84faf22d3b4fbebe17868cc210352e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=1021889), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2ef8a0b1350b47aba51fd8e7690f9bf6","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=1021889), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2d8cd771a9c84b1cb2921b5e1de9a4a0","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=256058), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d0e66fc48e334e9682072c8a05c695ad","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=256058), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Xw3lnSdSTu6Y","colab_type":"text"},"source":["## Build the Classifier"]},{"cell_type":"code","metadata":{"id":"-mddW8jF1JT7","colab_type":"code","colab":{}},"source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","\n","class Seq2VecNN(nn.Module):\n","  def __init__(self, vocab_size, num_classes, num_neurons_per_layer=[1000, 1000, 1000]):\n","\n","    super().__init__()\n","\n","    self.vocab_size = vocab_size\n","    self.num_classes = num_classes\n","\n","    layers = []\n","\n","    prev_layer_count = vocab_size\n","    for num_neurons in num_neurons_per_layer:\n","      layers.append(nn.Linear(prev_layer_count, num_neurons))\n","      layers.append(nn.ReLU())\n","      prev_layer_count = num_neurons\n","\n","    self.feedforward_layer = nn.Sequential(*layers)\n","\n","    self.output_layer = nn.Linear(prev_layer_count, self.num_classes)\n","      \n","  def forward(self, F):\n","    ''' Given a batch of sequences, and its sequence lengths, output a softmax of\n","        its class\n","\n","        Parameters\n","        ----------\n","        F : torch.LongTensor (N, self.vocab_size)\n","            It is a batch of bag-of-words\n","\n","        Returns\n","        -------\n","        logits_t : torch.FloatTensor (N, self.vocab_size)\n","            It is a un-normalized distribution over the classes for the n-th sequence:\n","            Pr_b(i) = softmax(logits_t[i]) for i in self.num_classes\n","    '''\n","    x = self.feedforward_layer(F)\n","    return self.output_layer(x)\n","        "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pnrmgmlvltFM","colab_type":"text"},"source":["## **Training:**\n","We are going to train our model and see if for each epoch it improves its predictions on the validation set\n","\n","How we train it:\n","* It uses teacher forcing:\n","  1. First, we have the source and target sentences\n","  2. Then, we feed the source sentence into the Encoder. The encoder returns the attended source sentence.\n","  3. Next, we feed the attended source sentence and the target sentence into the decoder\n","  4. We check if the output of the decoder is the same as the target sentence\n","\n","How we make predictions:\n","* It is similar to RNNs, where we feed in the source input to the encoder, feed in an SOS in the decoder, and we take the outputs of the previous decoder as inputs to the next decoder\n","* In more detail:\n","  1. First, we have the source sentence\n","  2. Then, we feed the source sentence into the Encoder to get an attended version of the source sentence\n","  3. Next, we feed an SOS token and the attended source sentence in the Decoder as the first input to our decoder\n","  4. We get the outputs of the decoder and use it as the next token to feed as the second input to our decoder\n","  5. Repeat 3-4 until we get an EOS token"]},{"cell_type":"markdown","metadata":{"id":"Ky1zEEBc-9jj","colab_type":"text"},"source":["### **How to train our model for one epoch:**"]},{"cell_type":"code","metadata":{"id":"TFyucOKm-8mb","colab_type":"code","colab":{}},"source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","\n","def train_for_one_epoch(model, loss_function, optimizer, train_dataloader, device):\n","  model.train()\n","\n","  train_loss = 0.0\n","  train_accuracy = 0.0\n","\n","  for F, Y in tqdm(train_dataloader, total=len(train_dataloader)):\n","\n","    # Send data to device\n","    F = F.to(device)\n","    Y = Y.to(device)   \n","\n","    # Forward-prop with the model\n","    optimizer.zero_grad()\n","    logits = model(F)\n","    \n","    # Compute the loss\n","    batch_loss = loss_function(logits, Y)\n","    train_loss += batch_loss.item()\n","\n","    # Compute the accuracy\n","    _, predictions = torch.max(torch.round(torch.sigmoid(logits)), 1)    \n","    batch_accuracy = predictions.eq(Y).sum().float().item() / Y.shape[0]\n","    train_accuracy += batch_accuracy\n","    \n","    batch_loss.backward()\n","    optimizer.step()\n","\n","    del F, Y\n","\n","  train_loss /= len(train_dataloader)\n","  train_accuracy /= len(train_dataloader)\n","\n","  return train_loss, train_accuracy\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u_EJIWKLB5-Q","colab_type":"text"},"source":["### **How to evaluate our model:**"]},{"cell_type":"code","metadata":{"id":"O7osWsSGCRYF","colab_type":"code","colab":{}},"source":["def evaluate_model(model, loss_function, test_dataloader, device):\n","\n","  model.eval()\n","\n","  eval_loss = 0\n","  eval_accuracy = 0\n","  num_sequences = 0\n","\n","  for F, Y in tqdm(test_dataloader, total=len(test_dataloader)):\n","\n","    # Send data to device\n","    F = F.to(device)\n","    Y = Y.to(device)\n","\n","    # Get predictions\n","    logits = model(F)\n","\n","    # Compute the loss\n","    eval_loss = loss_function(logits, Y).item()\n","\n","    # Compute the accuracy\n","    _, predictions = torch.max(torch.round(torch.sigmoid(logits)), 1)    \n","    batch_accuracy = predictions.eq(Y).sum().float().item() / Y.shape[0]\n","    eval_accuracy += batch_accuracy\n","\n","    del F, Y\n","\n","  eval_loss /= len(test_dataloader)\n","  eval_accuracy /= len(test_dataloader)\n","\n","  return eval_loss, eval_accuracy\n","  \n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3a1mV9JyQloy","colab_type":"text"},"source":["### **How to train our model for many epochs:**"]},{"cell_type":"code","metadata":{"id":"QcH_l2WvQoeT","colab_type":"code","outputId":"bc56d55a-ef5d-49a5-fa95-7f3d5870f5df","executionInfo":{"status":"ok","timestamp":1588224683175,"user_tz":240,"elapsed":2652302,"user":{"displayName":"Emilio Kartono","photoUrl":"","userId":"07780560173057852230"}},"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["3493f1a4cb63457db60846c2fc805e03"]}},"source":["import torch\n","from tqdm.notebook import tqdm\n","\n","def train():\n","    global combined_vocabs, train_dataloader, val_dataloader\n","\n","    device = torch.device(\"cuda\")\n","\n","    model = Seq2VecNN(len(combined_vocabs), 2, num_neurons_per_layer=[100, 25])\n","    model = model.to(device)\n","\n","    optimizer = torch.optim.Adam(model.parameters())\n","\n","    patience = 3 #float(\"inf\")\n","    num_epochs = float(\"inf\")\n","    \n","    best_eval_loss = float(\"inf\")\n","\n","    num_poor = 0\n","    epoch = 1\n","    \n","    while epoch <= num_epochs and num_poor < patience:\n","        \n","      loss_function = torch.nn.CrossEntropyLoss()\n","\n","      train_loss, train_accuracy = train_for_one_epoch(model, loss_function, optimizer, train_dataloader, device)\n","\n","      eval_loss, eval_accuracy = evaluate_model(model, loss_function, val_dataloader, device)\n","\n","      print(f'Epoch={epoch} Train-Loss={train_loss} Train-Acc={train_accuracy} Test-Loss={eval_loss} Test-Acc={eval_accuracy} Num-Poor={num_poor}')\n","\n","      if eval_loss >= best_eval_loss:\n","        num_poor += 1\n","\n","      else:\n","        num_poor = 0\n","        best_eval_loss = eval_loss\n","\n","      epoch += 1\n","\n","    return model\n","\n","trained_model = train()\n","\n","\n","    \n"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3493f1a4cb63457db60846c2fc805e03","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=47896), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"818193d666764cac9860615e79118c9a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=15966), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Epoch=1 Train-Loss=0.012065429525193669 Train-Acc=0.9932020680223819 Test-Loss=5.233084163942926e-06 Test-Acc=0.9932454121257672 Num-Poor=0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d06906e334764c22a2e73b01cadcee70","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=47896), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ea3914e9f49e46bdac2ac631951305aa","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=15966), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Epoch=2 Train-Loss=0.010305593614350598 Train-Acc=0.9935685304270364 Test-Loss=1.0664742213658607e-05 Test-Acc=0.9932003945885005 Num-Poor=0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9a01b71f934e40d6a9c1b040869f41ba","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=47896), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cebe143baf0443eeb804c69e9611503a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=15966), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Epoch=3 Train-Loss=0.010036695400318535 Train-Acc=0.9910672342158009 Test-Loss=3.3599010583647476e-11 Test-Acc=0.9934137385694601 Num-Poor=1\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c8984d5b3391438ba82d85c1d96ee4e9","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=47896), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"83a25bd2b71b468db46bc5a9e98814ff","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=15966), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Epoch=4 Train-Loss=0.009923419686731938 Train-Acc=0.9916603161015534 Test-Loss=2.0159406350188486e-10 Test-Acc=0.9931964800200426 Num-Poor=0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b8a75afa8aae4969bc1da9d2ea5329c4","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=47896), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"68ffef9c3989474882908aab3f92e91c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=15966), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Epoch=5 Train-Loss=0.009935518112526723 Train-Acc=0.98790935046768 Test-Loss=5.674499565238241e-10 Test-Acc=0.9931925654515846 Num-Poor=1\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"29a9d74e141d49efae353259b1a8f87a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=47896), HTML(value='')))"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"u_2tRoFYiyHv","colab_type":"text"},"source":["## **Testing**\n","We are going to test our model on the test set"]},{"cell_type":"code","metadata":{"id":"lbbgRHu7izQw","colab_type":"code","outputId":"f6b22713-709c-4c1e-fb00-57e71203e225","executionInfo":{"status":"ok","timestamp":1588225065472,"user_tz":240,"elapsed":88341,"user":{"displayName":"Emilio Kartono","photoUrl":"","userId":"07780560173057852230"}},"colab":{"base_uri":"https://localhost:8080/","height":83,"referenced_widgets":["d4e052e7596541fbb9b47423c2db7397","e6c9fcdf80774f75bb989e67c7dc710e","d74188e79d054ea5baaf1605fbdab9e3","d1a8da9653d64cfbb18d2439e7f7cdec","b7cc2a94570b404184a34ecd5893df99","60c1bcaf244d4c81a842a16387038207","df7aaceb2efb4be78ff9cc27a65e99fb","95fb768f956a4fbcba6b275f306e2685"]}},"source":["def test():\n","  ''' Used to test the model on the testing data'''\n","  global test_dataloader\n","  global trained_model\n","\n","  device = torch.device(\"cuda\")  \n","\n","  # Evaluate the model\n","  loss_function = torch.nn.CrossEntropyLoss()\n","  test_loss, test_accuracy = evaluate_model(trained_model, loss_function, test_dataloader, device)\n","\n","  print(f\"Test loss={test_loss}, Test Accuracy={test_accuracy}\")\n","\n","test()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d4e052e7596541fbb9b47423c2db7397","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=16001), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Test loss=2.8081064123368606e-06, Test Accuracy=0.9941644272232986\n"],"name":"stdout"}]}]}